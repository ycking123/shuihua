import requests
import logging
import re
import json
from typing import Optional, Dict, Any
from urllib.parse import urljoin

logger = logging.getLogger("URLCrawler")

def extract_meeting_url(text: str) -> Optional[str]:
    """
    ä»æ–‡æœ¬ä¸­æå–è…¾è®¯ä¼šè®®/ä¼ä¸šå¾®ä¿¡æ–‡æ¡£çš„ URL
    """
    # åŒ¹é…å¸¸è§çš„ä¼šè®®é“¾æ¥æ ¼å¼
    # https://meeting.tencent.com/p/xxx
    # https://meeting.tencent.com/wework/cloud-record/share?id=xxx
    url_pattern = r'(https?://(?:meeting\.tencent\.com|docs\.qq\.com|doc\.weixin\.qq\.com)/[^\s]+)'
    match = re.search(url_pattern, text)
    if match:
        return match.group(1)
    return None

def extract_json_object(text: str, start_index: int) -> Optional[str]:
    """Find the matching closing brace for a JSON object starting at start_index"""
    brace_count = 0
    in_string = False
    escape = False
    
    for i in range(start_index, len(text)):
        char = text[i]
        if in_string:
            if escape:
                escape = False
            elif char == '\\':
                escape = True
            elif char == '"':
                in_string = False
        else:
            if char == '"':
                in_string = True
            elif char == '{':
                brace_count += 1
            elif char == '}':
                brace_count -= 1
                if brace_count == 0:
                    return text[start_index:i+1]
    return None

def parse_meeting_html(html: str) -> Dict[str, Any]:
    """
    è§£æè…¾è®¯ä¼šè®® HTMLï¼Œæå– serverData ä¸­çš„å…ƒæ•°æ®
    """
    result = {
        "title": "æœªçŸ¥ä¼šè®®",
        "meeting_id": "",
        "duration": 0,
        "minutes_text": "",
        "recordings": []
    }
    
    try:
        # æŸ¥æ‰¾ Next.js çš„ hydration æ•°æ®: self.__next_f.push([1,"..."])
        pushes = re.finditer(r'self\.__next_f\.push\(\[(.*?)\]\)', html)
        
        for match in pushes:
            inner = match.group(1)
            parts = inner.split(',', 1)
            if len(parts) < 2: continue
            
            json_str_raw = parts[1].strip()
            
            # å°è¯•è§£æ JSON å­—ç¬¦ä¸²
            if json_str_raw.startswith('"') and json_str_raw.endswith('"'):
                try:
                    content = json.loads(json_str_raw)
                    if "serverData" in content:
                        sd_match = re.search(r'"serverData":(\{.*?\})', content)
                        if sd_match:
                            start = content.find('"serverData":') + len('"serverData":')
                            obj_str = extract_json_object(content, start)
                            if obj_str:
                                sd = json.loads(obj_str)
                                
                                # æå–å…³é”®ä¿¡æ¯
                                if "meeting_info" in sd:
                                    subject = sd["meeting_info"].get("subject", "")
                                    # å°è¯• Base64 è§£ç æ ‡é¢˜ (è…¾è®¯ä¼šè®®æ ‡é¢˜å¸¸ä¸º Base64)
                                    try:
                                        import base64
                                        decoded_subject = base64.b64decode(subject).decode('utf-8')
                                        result["title"] = decoded_subject
                                    except:
                                        result["title"] = subject
                                    
                                    result["meeting_id"] = sd["meeting_info"].get("meeting_id", "")
                                
                                result["duration"] = sd.get("total_recording_duration", 0)
                                result["recordings"] = sd.get("recordings", [])
                                
                                # æ£€æŸ¥æ˜¯å¦æœ‰çºªè¦æ–‡æœ¬ (ç›®å‰é€šå¸¸ä¸ºç©ºï¼Œéœ€è¦ API)
                                if "smart_minutes" in sd:
                                    result["minutes_text"] = str(sd["smart_minutes"])
                                
                                logger.info(f"âœ… æˆåŠŸæå–ä¼šè®®å…ƒæ•°æ®: {result['title']}")
                                return result
                except Exception as e:
                    continue
                    
    except Exception as e:
        logger.error(f"âŒ è§£æ HTML å¤±è´¥: {e}")
        
    return result

def crawl_and_parse_meeting(url: str, cookies_str: str) -> Optional[Dict[str, Any]]:
    """
    çˆ¬å–å¹¶è§£æä¼šè®®å†…å®¹ (å…¥å£å‡½æ•°)
    """
    html = fetch_content_with_cookies(url, cookies_str)
    if not html:
        return None
    
    return parse_meeting_html(html)

def fetch_content_with_cookies(url: str, cookies_str: str) -> Optional[str]:
    """
    ä½¿ç”¨ç”¨æˆ·æä¾›çš„ Cookie çˆ¬å–é¡µé¢å†…å®¹
    """
    if not cookies_str:
        logger.warning("âš ï¸ æœªæä¾› Cookieï¼Œæ— æ³•çˆ¬å–å—ä¿æŠ¤çš„ä¼šè®®é¡µé¢")
        return None

    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Cookie": cookies_str
    }

    try:
        logger.info(f"ğŸ•·ï¸ æ­£åœ¨å°è¯•çˆ¬å– URL: {url}")
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        
        content = response.text
        
        # 1. æ£€æµ‹ JavaScript é‡å®šå‘
        # window.location.replace("...") æˆ– window.location.href = "..."
        redirect_pattern = r'window\.location\.(?:replace|href)\s*\(?\s*["\']([^"\']+)["\']'
        redirect_match = re.search(redirect_pattern, content)
        if redirect_match:
            new_url = redirect_match.group(1)
            logger.info(f"ğŸ”„ æ£€æµ‹åˆ° JS é‡å®šå‘ï¼Œæ­£åœ¨è·³è½¬è‡³: {new_url}")
            # å¤„ç†ç›¸å¯¹è·¯å¾„
            if new_url.startswith('/'):
                 # ç®€å•æå–åŸŸå
                 from urllib.parse import urljoin
                 new_url = urljoin(url, new_url)
            
            # é€’å½’è°ƒç”¨ (é˜²æ­¢æ­»å¾ªç¯å¯ä»¥åŠ ä¸ªè®¡æ•°å™¨ï¼Œè¿™é‡Œç®€å•å¤„ç†)
            return fetch_content_with_cookies(new_url, cookies_str)

        logger.info(f"âœ… çˆ¬å–æˆåŠŸï¼Œè·å–åˆ° {len(content)} å­—ç¬¦")
        return content
    except Exception as e:
        logger.error(f"âŒ çˆ¬å–å¤±è´¥: {e}")
        return None
